{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Atari Breakout: Deep Q-Learning"
      ],
      "metadata": {
        "id": "o9mWUxe_M1js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breakout je klasická hra ze starých počítačů a konzolí. Pamatujete si ji z úvodu?\n",
        "\n",
        "Tento příklad je výpočetně velice náročný (agent vidí pouze vizuální data), potřebuje tedy výkonnou grafickou kartu a dlouhý čas na trénink."
      ],
      "metadata": {
        "id": "rB6PIojXbV7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "N2T-wyfgqDtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra,atari]\n",
        "!apt-get install -y xvfb python3-opengl\n",
        "!pip install gymnasium PyOpenGL pyvirtualdisplay\n",
        "!pip install imageio"
      ],
      "metadata": {
        "id": "MYHCPRw3bc_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import io\n",
        "import imageio.v3 as iio\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from stable_baselines3 import PPO, DQN\n",
        "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "# Ignore IMAGEIO FFMPEG_WRITER WARNING\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"imageio_ffmpeg\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_root = '/content/gdrive/My Drive/Colab Notebooks/Discover - Machine Learning/Models'"
      ],
      "metadata": {
        "id": "9vi2p7C2pmz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_atari_env('BreakoutNoFrameskip-v4', n_envs=16)\n",
        "env = VecFrameStack(env, n_stack=4)\n",
        "env.metadata['render_fps'] = 30"
      ],
      "metadata": {
        "id": "szMLIcwdptFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not torch.cuda.is_available:\n",
        "  # CPU - TEST\n",
        "  LEARNING_STARTS = 1_000\n",
        "  BUFFER_SIZE = 5_000\n",
        "  TOTAL_TIMESTEPS = 10_000\n",
        "  REPEAT_TRAINING = 4\n",
        "else:\n",
        "  # CUDA\n",
        "  LEARNING_STARTS = 20_000\n",
        "  BUFFER_SIZE = 200_000\n",
        "  TOTAL_TIMESTEPS = 500_000\n",
        "  REPEAT_TRAINING = 20\n",
        "\n",
        "BUFFER_SIZE"
      ],
      "metadata": {
        "id": "OzEWVc28pvP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTION FOR RENDERING\n",
        "PLOT_SINGLE_ENV = True\n",
        "\n",
        "\n",
        "def get_frames(env, model=None, max_steps=500):\n",
        "    # either render random behavior or a policy given by the model, if provided\n",
        "    if model is None:\n",
        "      get_action = lambda obs: [\n",
        "          env.action_space.sample() for _ in range(len(obs))]\n",
        "    else:\n",
        "      get_action = lambda obs: model.predict(obs, deterministic=True)[0]\n",
        "    crop_img = lambda img: img[:210, :160].copy() if PLOT_SINGLE_ENV else img\n",
        "\n",
        "    images = []\n",
        "    obs = env.reset()\n",
        "    img = env.render('rgb_array')\n",
        "    images.append(crop_img(img))\n",
        "\n",
        "    for i in range(max_steps):\n",
        "        action = get_action(obs)\n",
        "        obs, *_ = env.step(action)\n",
        "        img = env.render('rgb_array')\n",
        "        images.append(crop_img(img))\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def show_frames(frames, width=None):\n",
        "  mp4_image = iio.imwrite(\"<bytes>\", frames, extension=\".mp4\")\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4_image).decode()\n",
        "\n",
        "  return HTML(f\"\"\"\n",
        "  <video {\"\" if width is None else \"width=\" + str(width) + \" \"}controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url)\n",
        "\n",
        "\n",
        "def render_env(env, model=None, max_steps=500, width=None):\n",
        "  frames = get_frames(env, model=model, max_steps=max_steps)\n",
        "  # fix the dimensions for conversion to video\n",
        "  h, w = frames[0].shape[:2]\n",
        "  h = (h // 16) * 16\n",
        "  w = (w // 16) * 16\n",
        "  frames = [f[:h, :w, :] for f in frames]\n",
        "  return show_frames(frames, width=width)"
      ],
      "metadata": {
        "id": "NQuHmhchp2K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "render_env(env)"
      ],
      "metadata": {
        "id": "gE60X7IxqRQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DQN('CnnPolicy', env, verbose=0, learning_starts=LEARNING_STARTS,\n",
        "            buffer_size=BUFFER_SIZE)"
      ],
      "metadata": {
        "id": "iQbvHy2vp4bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "\n",
        "t0 = datetime.now()\n",
        "print(f'{t0} -- Starting training.')\n",
        "timesteps = 0\n",
        "\n",
        "for i in range(REPEAT_TRAINING):\n",
        "  model.learn(total_timesteps=TOTAL_TIMESTEPS)\n",
        "  tt = datetime.now()\n",
        "  timesteps += model.num_timesteps\n",
        "  print(f'{tt} -- Finished iteration {i + 1} / {REPEAT_TRAINING}, elapsed {tt - t0},'\n",
        "        f' total timesteps {timesteps:,}')\n",
        "  # store it under a new file name, so I do not overwrite the existing ones\n",
        "  model.save(f'{model_root}/new_breakout_model_{i}')"
      ],
      "metadata": {
        "id": "HTKNORCIp5nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ffvgv7qzp5h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What has the agent learnt?"
      ],
      "metadata": {
        "id": "ELVaZqrDp5Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_atari_env('BreakoutNoFrameskip-v4', n_envs=16)\n",
        "env = VecFrameStack(env, n_stack=4)\n",
        "env.metadata['render_fps'] = 30"
      ],
      "metadata": {
        "id": "njqZHXpUqLpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Untrained agent (random)"
      ],
      "metadata": {
        "id": "Kz4WG2l3qf3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "render_env(env, width=400)"
      ],
      "metadata": {
        "id": "eVgOTabRqeCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trained models"
      ],
      "metadata": {
        "id": "I7tRWOwYqih-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(model_root)"
      ],
      "metadata": {
        "id": "8L1qiQOvrGvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'breakout_model'"
      ],
      "metadata": {
        "id": "X2-68Y0UuFMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0  # After 500k steps, about 15 minutes of training\n",
        "model = DQN.load(f'{model_root}/{model_name}_{i}')"
      ],
      "metadata": {
        "id": "8xRawMxuql_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "_ynzd67jrMXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "render_env(env, model=model, width=400)"
      ],
      "metadata": {
        "id": "r4_IQ-bvrNKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 3  # After 2M steps, about 1 hour of training\n",
        "model = DQN.load(f'{model_root}/{model_name}_{i}')\n",
        "render_env(env, model=model, width=400)"
      ],
      "metadata": {
        "id": "8vYNAPCFsBZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 19  # After 10M steps, almost 5 hours of training\n",
        "model = DQN.load(f'{model_root}/{model_name}_{i}')\n",
        "render_env(env, model=model, width=400)"
      ],
      "metadata": {
        "id": "UBCccD_RscDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Not as good as Deepmind's model!\n",
        "- **Playing Atari with Deep Reinforcement Learning**\n",
        "- https://arxiv.org/abs/1312.5602\n",
        "\n",
        "\n",
        "At the same time, we have very basic setup, 10 years ago this was quite a milestone to achieve and it was necessary to be Deepmind / Google to train such models. Basically everybody can do it now and we even't haven't pulled out all the tricks.\n",
        "\n",
        "It is possible to use different learning algorithms, to tweak hyperparameters, to have longer training, to use multiple GPUs (distributed training is not simple, but everybody uses it nowadays).\n",
        "\n",
        "At the same time, it costs money: using larger machine with good GPU on Colab costs about $1 per hour.\n",
        "\n",
        "Estimations for the compute costs of training large language models are about 1M dollars per 1B of parameters. Basic ChatGPT has 175B parameters and GPT-4 is estimated to have about 10x as much. That's really expensive and only the biggest players can do it. Nvidia is hot."
      ],
      "metadata": {
        "id": "BP4uXE7Qs36g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ti1W4qEteEI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}